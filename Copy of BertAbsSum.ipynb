{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"colab":{"name":"Copy of BertAbsSum.ipynb","provenance":[{"file_id":"https://github.com/brs1977/BERT-Transformer-for-Summarization/blob/master/BertAbsSum.ipynb","timestamp":1578858533929}],"collapsed_sections":["3gPAjtjbjaZ0","xHNngTAigSk9"],"toc_visible":true},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"2DKufDQceuaD","colab_type":"code","outputId":"9fbfa809-2e33-4cf4-cb53-df63906c6690","executionInfo":{"status":"ok","timestamp":1579148415466,"user_tz":-180,"elapsed":48440,"user":{"displayName":"Bukin Ruslan","photoUrl":"","userId":"02589038028886526730"}},"colab":{"base_uri":"https://localhost:8080/","height":125}},"source":["#kaggle .345\n","\n","from google.colab import drive, files\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"U7h5IEsJfJs7","colab_type":"text"},"source":["##Get Kaggle data"]},{"cell_type":"code","metadata":{"id":"rJ7V-uhSfIYk","colab_type":"code","outputId":"fa26bb3e-3cc9-4a12-9103-105d39a5a2d1","executionInfo":{"status":"ok","timestamp":1579148557599,"user_tz":-180,"elapsed":7254,"user":{"displayName":"Bukin Ruslan","photoUrl":"","userId":"02589038028886526730"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#!pip install -q kaggle\n","\n","#kaggle key\n","!mkdir ~/.kaggle\n","!cp /content/drive/My\\ Drive/kaggle.json ~/.kaggle\n","!ls ~/.kaggle"],"execution_count":11,"outputs":[{"output_type":"stream","text":["kaggle.json\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1h32t1QHfQk8","colab_type":"code","outputId":"69a75f46-526d-4f00-9ecb-5065aa7ccc79","executionInfo":{"status":"ok","timestamp":1579148566216,"user_tz":-180,"elapsed":8598,"user":{"displayName":"Bukin Ruslan","photoUrl":"","userId":"02589038028886526730"}},"colab":{"base_uri":"https://localhost:8080/","height":246}},"source":["!kaggle competitions download -c title-generation"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n","Downloading test.csv to /content/bertsum\n","  0% 0.00/905k [00:00<?, ?B/s]\n","100% 905k/905k [00:00<00:00, 60.1MB/s]\n","Downloading vocs.pkl.zip to /content/bertsum\n"," 78% 5.00M/6.39M [00:00<00:00, 23.3MB/s]\n","100% 6.39M/6.39M [00:00<00:00, 25.3MB/s]\n","Downloading train.csv.zip to /content/bertsum\n"," 91% 40.0M/43.7M [00:00<00:00, 27.9MB/s]\n","100% 43.7M/43.7M [00:00<00:00, 50.1MB/s]\n","Downloading sample_submission.csv.zip to /content/bertsum\n","  0% 0.00/778k [00:00<?, ?B/s]\n","100% 778k/778k [00:00<00:00, 263MB/s]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XpltIhc-fVqS","colab_type":"code","outputId":"e4ea759e-0f67-4a4e-b7fb-f82223bc5b0d","executionInfo":{"status":"ok","timestamp":1579148580967,"user_tz":-180,"elapsed":14736,"user":{"displayName":"Bukin Ruslan","photoUrl":"","userId":"02589038028886526730"}},"colab":{"base_uri":"https://localhost:8080/","height":140}},"source":["!mkdir data\n","!unzip sample_submission.csv.zip -d data\n","!unzip vocs.pkl.zip -d data\n","!unzip train.csv.zip -d data\n","!mv test.csv data\n","\n","!ls data"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Archive:  sample_submission.csv.zip\n","  inflating: data/sample_submission.csv  \n","Archive:  vocs.pkl.zip\n","  inflating: data/vocs.pkl           \n","Archive:  train.csv.zip\n","  inflating: data/train.csv          \n","sample_submission.csv  test.csv  train.csv  vocs.pkl\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OiawlFnGfbV7","colab_type":"code","colab":{}},"source":["import pandas as pd\n","\n","#train = pd.read_csv('../data/train.csv', encoding='utf8')\n","# test = pd.read_csv('data/test.csv', encoding='utf8')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0288Y3gPfc8a","colab_type":"code","outputId":"e0b8b8a7-b169-4d48-e77d-45b6051d3eb5","executionInfo":{"status":"ok","timestamp":1578844940608,"user_tz":-180,"elapsed":1063,"user":{"displayName":"","photoUrl":"","userId":""}},"colab":{"base_uri":"https://localhost:8080/","height":195}},"source":["train.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>abstract</th>\n","      <th>title</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>we consider the problem of utility maximizatio...</td>\n","      <td>on optimal investment with processes of long o...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>in this paper we provide an explicit formula f...</td>\n","      <td>boolean complexes for ferrers graphs</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>kinesin-5, also known as eg5 in vertebrates is...</td>\n","      <td>relative velocity of sliding of microtubules b...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>we discuss the transition paths in a coupled b...</td>\n","      <td>bifurcation of transition paths induced by cou...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>two types of room temperature detectors of ter...</td>\n","      <td>all-electric detectors of the polarization sta...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            abstract                                              title\n","0  we consider the problem of utility maximizatio...  on optimal investment with processes of long o...\n","1  in this paper we provide an explicit formula f...               boolean complexes for ferrers graphs\n","2  kinesin-5, also known as eg5 in vertebrates is...  relative velocity of sliding of microtubules b...\n","3  we discuss the transition paths in a coupled b...  bifurcation of transition paths induced by cou...\n","4  two types of room temperature detectors of ter...  all-electric detectors of the polarization sta..."]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"a_xxfYeqjig3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"3660f2b6-1568-480e-ea05-8482986a8f9f","executionInfo":{"status":"ok","timestamp":1578980388090,"user_tz":-180,"elapsed":1038,"user":{"displayName":"Bukin Ruslan","photoUrl":"","userId":"02589038028886526730"}}},"source":["#len(train.title[0].split(' '))\n","max(map(lambda x : len(x.split(' ')), train.title))"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["47"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"5CjNvi4nfhFc","colab_type":"text"},"source":["##Requirements"]},{"cell_type":"code","metadata":{"id":"FWO9FdL0fB5v","colab_type":"code","outputId":"35d4de72-34a3-466c-c4c8-b34bf1c84bf0","executionInfo":{"status":"ok","timestamp":1579148458165,"user_tz":-180,"elapsed":8284,"user":{"displayName":"Bukin Ruslan","photoUrl":"","userId":"02589038028886526730"}},"colab":{"base_uri":"https://localhost:8080/","height":175}},"source":["%cd /content\n","!rm bertsum -r\n","!git clone https://github.com/brs1977/BERT-Transformer-for-Summarization bertsum\n","\n","# !git pull origin master"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content\n","rm: cannot remove 'bertsum': No such file or directory\n","Cloning into 'bertsum'...\n","remote: Enumerating objects: 105, done.\u001b[K\n","remote: Counting objects: 100% (105/105), done.\u001b[K\n","remote: Compressing objects: 100% (77/77), done.\u001b[K\n","remote: Total 105 (delta 47), reused 76 (delta 27), pack-reused 0\u001b[K\n","Receiving objects: 100% (105/105), 107.04 KiB | 637.00 KiB/s, done.\n","Resolving deltas: 100% (47/47), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Cq77ji8Wow4T","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"4e32ac50-0c33-431b-b2a6-ec9312223d5e","executionInfo":{"status":"ok","timestamp":1578893267399,"user_tz":-180,"elapsed":1655,"user":{"displayName":"Bukin Ruslan","photoUrl":"","userId":"02589038028886526730"}}},"source":["%cd /content/bertsum"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/content/bertsum\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qvZ-_YvEeQLk","colab_type":"code","outputId":"0025b8ee-befb-4d4b-9ab7-32e6f3535cee","executionInfo":{"status":"ok","timestamp":1579175563485,"user_tz":-180,"elapsed":2104,"user":{"displayName":"Bukin Ruslan","photoUrl":"","userId":"02589038028886526730"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd /content/bertsum\n","\n","import torch\n","from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n","                              TensorDataset)\n","import argparse\n","import logging\n","import os\n","import json\n","import time\n","import torch.nn.functional as F\n","from preprocess import CSVProcessor, create_dataset\n","from model import BertAbsSum\n","from pytorch_pretrained_bert.tokenization import BertTokenizer\n","from pytorch_pretrained_bert.modeling import BertModel\n","from pytorch_pretrained_bert.optimization import BertAdam\n","from preprocess import convert_examples_to_features\n","from tqdm import tqdm, trange\n","from transformer import Constants"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/content/bertsum\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VYvyMXe7f69f","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FB-lgaRTf7A1","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MBJiX709huHD","colab_type":"text"},"source":["##Train"]},{"cell_type":"markdown","metadata":{"id":"FuFtKU0eiDwi","colab_type":"text"},"source":["###Bert config"]},{"cell_type":"code","metadata":{"id":"oRj0gX06eQLo","colab_type":"code","colab":{}},"source":["logging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n","                    datefmt='%m/%d/%Y %H:%M:%S',\n","                    level=logging.INFO)\n","logger = logging.getLogger(__name__)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uelhDbCjeQLq","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HQBqPZK9eQLt","colab_type":"code","colab":{}},"source":["class ARGS(object):\n","    data_dir = 'data/processed_data'\n","    bert_model = 'bert-base-uncased'\n","    #output_dir = 'output'\n","    output_dir = '/content/drive/My Drive/nlp/nlp_model'\n","    checkpoint = None\n","    GPU_index = 0\n","    learning_rate = 1e-4\n","    num_train_epochs = 3\n","    warmup_proportion = 0.1\n","    max_src_len = 256\n","    max_tgt_len = 45\n","    train_batch_size = 16\n","    valid_batch_size = 16\n","    val_split = .01\n","    decoder_config = None\n","    print_every = 500\n","    gradient_accumulation_steps = 16 # 256 / train_batch_size \n","\n","\n","args = ARGS()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uH4VXzObeQLx","colab_type":"code","outputId":"d7e6227e-ff76-472c-dab7-807acaa9c63d","executionInfo":{"status":"ok","timestamp":1579175571434,"user_tz":-180,"elapsed":1079,"user":{"displayName":"Bukin Ruslan","photoUrl":"","userId":"02589038028886526730"}},"colab":{"base_uri":"https://localhost:8080/","height":72}},"source":["if torch.cuda.is_available():\n","    device = torch.device('cuda', args.GPU_index)\n","else:\n","    device = torch.device('cpu')\n","logger.info(f'Using device:{device}')\n","\n","if not os.path.exists(args.output_dir):\n","    os.makedirs(args.output_dir)\n","model_path = os.path.join(args.output_dir, time.strftime('model_%m-%d-%H:%M:%S', time.localtime()))\n","os.mkdir(model_path)\n","logger.info(f'Saving model to {model_path}.')\n","\n","if args.decoder_config is not None:\n","    with open(args.decoder_config, 'r') as f:\n","        decoder_config = json.load(f)\n","else:\n","    with open(os.path.join(args.bert_model, 'bert_config.json'), 'r') as f:\n","        bert_config = json.load(f)\n","        decoder_config = {}\n","        decoder_config = {}\n","        decoder_config['len_max_seq'] = args.max_tgt_len\n","        decoder_config['d_word_vec'] = bert_config['hidden_size']\n","        decoder_config['n_layers'] = 8\n","        decoder_config['n_head'] = 12\n","        decoder_config['d_k'] = 64\n","        decoder_config['d_v'] = 64\n","        decoder_config['d_model'] = bert_config['hidden_size']\n","        decoder_config['d_inner'] = bert_config['hidden_size']\n","        decoder_config['vocab_size'] = bert_config['vocab_size']        "],"execution_count":4,"outputs":[{"output_type":"stream","text":["01/16/2020 11:52:50 - INFO - __main__ -   Using device:cuda:0\n","01/16/2020 11:52:50 - INFO - __main__ -   Saving model to /content/drive/My Drive/nlp/nlp_model/model_01-16-11:52:50.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"HE6VE9npiQ6t","colab_type":"text"},"source":["###Data Loaders"]},{"cell_type":"code","metadata":{"id":"SilaS4EigFGy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"outputId":"59d9527e-0a9c-4462-9803-aadc702612a2","executionInfo":{"status":"ok","timestamp":1579175633539,"user_tz":-180,"elapsed":19389,"user":{"displayName":"Bukin Ruslan","photoUrl":"","userId":"02589038028886526730"}}},"source":["#prepared data\n","train_data  = torch.load('/content/drive/My Drive/nlp/nlp_model/abs_bert/data256X45/train.pt')\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=args.train_batch_size, drop_last=True)\n","\n","valid_data = torch.load('/content/drive/My Drive/nlp/nlp_model/abs_bert/data256X45/valid.pt')\n","valid_sampler = RandomSampler(valid_data)\n","valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=args.valid_batch_size, drop_last=True)\n","\n","tokenizer = BertTokenizer.from_pretrained(args.bert_model)\n","\n","\n","#torch.save(train_data,'train.pt')\n","#torch.save(valid_data,'valid.pt')\n","#!cp *.pt /content/drive/My\\ Drive/nlp/nlp_model/data\n","# !ls /content/drive/My\\ Drive/nlp/nlp_model/data -la\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["01/16/2020 11:53:52 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"3gPAjtjbjaZ0","colab_type":"text"},"source":["####Preprocess"]},{"cell_type":"code","metadata":{"id":"uok4w6IzVo7V","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":389},"outputId":"250f5a5c-275b-4a0a-df1c-812418e78b39","executionInfo":{"status":"ok","timestamp":1579062913148,"user_tz":-180,"elapsed":356216,"user":{"displayName":"Bukin Ruslan","photoUrl":"","userId":"02589038028886526730"}}},"source":["# %%capture\n","\n","is_test = False\n","nrows = None if not is_test else 500\n","\n","# data preprocess\n","processor = CSVProcessor(random_split=args.val_split)\n","tokenizer = BertTokenizer.from_pretrained(args.bert_model)\n","# tokenizer = BertTokenizer.from_pretrained(os.path.join(args.bert_model, 'vocab.txt'))\n","logger.info('Loading train examples...')\n","train_examples = processor.get_train_examples('../data/train.csv', nrows = nrows)\n","num_train_optimization_steps = int(len(train_examples) / args.train_batch_size / args.gradient_accumulation_steps) * args.num_train_epochs\n","logger.info('Converting train examples to features...')\n","train_features = convert_examples_to_features(train_examples, args.max_src_len, args.max_tgt_len, tokenizer)\n","example = train_examples[0]\n","example_feature = train_features[0]\n","logger.info(\"*** Example ***\")\n","logger.info(\"guid: %s\" % (example.guid))\n","logger.info(\"src text: %s\" % example.src)\n","logger.info(\"src_ids: %s\" % \" \".join([str(x) for x in example_feature.src_ids]))\n","logger.info(\"src_mask: %s\" % \" \".join([str(x) for x in example_feature.src_mask]))\n","logger.info(\"tgt text: %s\" % example.tgt)\n","logger.info(\"tgt_ids: %s\" % \" \".join([str(x) for x in example_feature.tgt_ids]))\n","logger.info(\"tgt_mask: %s\" % \" \".join([str(x) for x in example_feature.tgt_mask]))\n","logger.info('Building dataloader...')\n","train_data = create_dataset(train_features)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=args.train_batch_size, drop_last=True)\n","\n","valid_examples = processor.get_valid_examples('../data/train.csv')\n","logger.info('Converting valid examples to features...')\n","valid_features = convert_examples_to_features(valid_examples, args.max_src_len, args.max_tgt_len, tokenizer)\n","valid_data = create_dataset(valid_features)\n","valid_sampler = RandomSampler(valid_data)\n","valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=args.valid_batch_size, drop_last=True)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["01/15/2020 04:29:17 - INFO - pytorch_pretrained_bert.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache, downloading to /tmp/tmpbt3wpshc\n","100%|██████████| 231508/231508 [00:00<00:00, 1250985.48B/s]\n","01/15/2020 04:29:18 - INFO - pytorch_pretrained_bert.file_utils -   copying /tmp/tmpbt3wpshc to cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","01/15/2020 04:29:18 - INFO - pytorch_pretrained_bert.file_utils -   creating metadata file for /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","01/15/2020 04:29:18 - INFO - pytorch_pretrained_bert.file_utils -   removing temp file /tmp/tmpbt3wpshc\n","01/15/2020 04:29:18 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","01/15/2020 04:29:18 - INFO - __main__ -   Loading train examples...\n","01/15/2020 04:29:31 - INFO - __main__ -   Converting train examples to features...\n","examples: 100%|██████████| 133621/133621 [05:35<00:00, 397.73it/s]\n","01/15/2020 04:35:07 - INFO - __main__ -   *** Example ***\n","01/15/2020 04:35:07 - INFO - __main__ -   guid: 0\n","01/15/2020 04:35:07 - INFO - __main__ -   src text: we consider the problem of utility maximization for investors with power utility functions. building on the earlier work larsen et al. (2016), we prove that the value of the problem is a frechet-differentiable function of the drift of the price process, provided that this drift lies in a suitable banach space.   we then study optimal investment problems with non-markovian driving processes. in such models there is no hope to get a formula for the achievable maximal utility. applying results of the first part of the paper we provide first order expansions for certain problems involving fractional brownian motion either in the drift or in the volatility. we also point out how asymptotic results can be derived for models with strong mean reversion.\n","01/15/2020 04:35:07 - INFO - __main__ -   src_ids: 101 2057 5136 1996 3291 1997 9710 20446 3989 2005 9387 2007 2373 9710 4972 1012 2311 2006 1996 3041 2147 20094 3802 2632 1012 1006 2355 1007 1010 2057 6011 2008 1996 3643 1997 1996 3291 2003 1037 10424 27635 2102 1011 2367 19210 3853 1997 1996 11852 1997 1996 3976 2832 1010 3024 2008 2023 11852 3658 1999 1037 7218 7221 6776 2686 1012 2057 2059 2817 15502 5211 3471 2007 2512 1011 28003 18073 4439 6194 1012 1999 2107 4275 2045 2003 2053 3246 2000 2131 1037 5675 2005 1996 9353 4048 13331 3468 29160 9710 1012 11243 3463 1997 1996 2034 2112 1997 1996 3259 2057 3073 2034 2344 4935 2015 2005 3056 3471 5994 12884 2389 2829 2937 4367 2593 1999 1996 11852 2030 1999 1996 5285 10450 18605 1012 2057 2036 2391 2041 2129 2004 24335 13876 20214 3463 2064 2022 5173 2005 4275 2007 2844 2812 7065 2545 3258 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","01/15/2020 04:35:07 - INFO - __main__ -   src_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","01/15/2020 04:35:07 - INFO - __main__ -   tgt text: on optimal investment with processes of long or negative memory\n","01/15/2020 04:35:07 - INFO - __main__ -   tgt_ids: 101 2006 15502 5211 2007 6194 1997 2146 2030 4997 3638 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","01/15/2020 04:35:07 - INFO - __main__ -   tgt_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","01/15/2020 04:35:07 - INFO - __main__ -   Building dataloader...\n","01/15/2020 04:35:09 - INFO - __main__ -   Converting valid examples to features...\n","examples: 100%|██████████| 1379/1379 [00:03<00:00, 413.68it/s]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"-b1kpKY7gB4D","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"FifT478VfGUU","colab_type":"code","colab":{}},"source":["\n","# with open('filename.pickle', 'wb') as handle:\n","#     pickle.dump(a, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","# with open('filename.pickle', 'rb') as handle:\n","#     b = pickle.load(handle)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YgeH3YrqWuvI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"f86323bd-7424-49cd-a3a7-1527828f0997","executionInfo":{"status":"ok","timestamp":1578999441296,"user_tz":-180,"elapsed":1043,"user":{"displayName":"Bukin Ruslan","photoUrl":"","userId":"02589038028886526730"}}},"source":["# valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=args.valid_batch_size, drop_last=True)\n","# for batch  in valid_dataloader:\n","#   break\n","# batch[0].shape"],"execution_count":44,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([8, 256])"]},"metadata":{"tags":[]},"execution_count":44}]},{"cell_type":"markdown","metadata":{"id":"kNny66w7ioT7","colab_type":"text"},"source":["###Loss functions"]},{"cell_type":"code","metadata":{"id":"Hx8bd6jR3C_n","colab_type":"code","colab":{}},"source":["def cal_performance(logits, ground, smoothing=True):\n","    ground = ground[:, 1:]\n","    logits = logits.view(-1, logits.size(-1))\n","    ground = ground.contiguous().view(-1)\n","\n","    loss = cal_loss(logits, ground, smoothing=smoothing)\n","\n","    pad_mask = ground.ne(Constants.PAD)\n","    pred = logits.max(-1)[1]\n","    correct = pred.eq(ground)\n","    correct = correct.masked_select(pad_mask).sum().item()\n","    return loss, correct\n","\n","def cal_loss(logits, ground, smoothing=True):\n","    def label_smoothing(logits, labels):\n","        eps = 0.1\n","        num_classes = logits.size(-1)\n","\n","        # >>> z = torch.zeros(2, 4).scatter_(1, torch.tensor([[2], [3]]), 1.23)\n","        # >>> z\n","        # tensor([[ 0.0000,  0.0000,  1.2300,  0.0000],\n","        #        [ 0.0000,  0.0000,  0.0000,  1.2300]])\n","        one_hot = torch.zeros_like(logits).scatter(1, labels.view(-1, 1), 1)\n","        one_hot = one_hot * (1 - eps) + (1 - one_hot) * eps / (num_classes - 1)\n","        log_prb = F.log_softmax(logits, dim=1)\n","        non_pad_mask = ground.ne(Constants.PAD)\n","        loss = -(one_hot * log_prb).sum(dim=1)\n","        loss = loss.masked_select(non_pad_mask).mean()\n","        return loss\n","    if smoothing:\n","        loss = label_smoothing(logits, ground)\n","    else:\n","        loss = F.cross_entropy(logits, ground, ignore_index=Constants.PAD)\n","    \n","    return loss    \n","\n","def rouge(hyp, ref, n):\n","    scores = []\n","    for h, r in zip(hyp, ref):\n","        r = re.sub(r'[UNK]', '', r)\n","        r = re.sub(r'[’!\"#$%&\\'()*+,-./:：？！《》;<=>?@[\\\\]^_`{|}~]+', '', r)\n","        r = re.sub(r'\\d', '', r)\n","        r = re.sub(r'[a-zA-Z]', '', r)\n","        count = 0\n","        match = 0\n","        for i in range(len(r) - n):\n","            gram = r[i:i + n]\n","            if gram in h:\n","                match += 1\n","            count += 1\n","        scores.append(0 if count==0 else match / count)\n","    return np.average(scores)\n","\n","def convert_one_example(text, src_max_seq_length, tokenizer):\n","    src_tokens = tokenizer.tokenize(text)\n","    if len(src_tokens) > src_max_seq_length - 2:\n","        src_tokens = src_tokens[:(src_max_seq_length - 2)]\n","    src_tokens = [\"[CLS]\"] + src_tokens + [\"[SEP]\"]\n","\n","    src_ids = tokenizer.convert_tokens_to_ids(src_tokens)\n","\n","    src_mask = [1] * len(src_ids)\n","    src_padding = [0] * (src_max_seq_length - len(src_ids))\n","    src_ids += src_padding\n","    src_mask += src_padding\n","\n","    return torch.tensor([src_ids]), torch.tensor([src_mask])    "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o1dhUYPgjhW3","colab_type":"text"},"source":["###Validation function"]},{"cell_type":"code","metadata":{"id":"BSNeu5s1jlGK","colab_type":"code","colab":{}},"source":["import re\n","import numpy as np\n","def do_validate():\n","  logger.info(\"***** Running validation *****\")\n","  model.eval()\n","  hyp_list = []\n","  ref_list = []\n","  i = 0\n","  for batch in tqdm(valid_dataloader, desc=\"Val iter\", position=0):\n","      i += 1\n","      batch = tuple(t.to(device) for t in batch)\n","      pred, _ = model.beam_decode(batch[0], batch[1], 3, 3)\n","      src, tgt = batch[0], batch[2]\n","      for i in range(args.valid_batch_size):\n","          # sample_src = \"\".join(tokenizer.convert_ids_to_tokens(src[i].cpu().numpy())).split('[CLS]')[1].split('[SEP]')[0] + '\\n'\n","          sample_tgt = \"\".join(tokenizer.convert_ids_to_tokens(tgt[i].cpu().numpy())).split('[CLS]')[1].split('[SEP]')[0] + '\\n'\n","          sample_pred = \"\".join(tokenizer.convert_ids_to_tokens(pred[i][0])).split('[SEP]')[0] + '\\n'\n","\n","          hyp_list.append(sample_pred)\n","          ref_list.append(sample_tgt)\n","  rouge_1 = rouge(hyp_list, ref_list, 1)\n","  rouge_2 = rouge(hyp_list, ref_list, 2)\n","  logger.info('******Validation results******')\n","  logger.info(f'Rouge-1: {rouge_1}')\n","  logger.info(f'Rouge-2: {rouge_2}')\n","  logger.info('Validation finished.')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QtGK6INWjlKP","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JLh3CyBgiZKB","colab_type":"text"},"source":["###Model"]},{"cell_type":"code","metadata":{"id":"p7Q9fMBjsBHP","colab_type":"code","outputId":"4f18b956-0ce4-4329-905a-6c021a770a3d","executionInfo":{"status":"ok","timestamp":1579175673477,"user_tz":-180,"elapsed":13751,"user":{"displayName":"Bukin Ruslan","photoUrl":"","userId":"02589038028886526730"}},"colab":{"base_uri":"https://localhost:8080/","height":318}},"source":["num_train_optimization_steps = int(len(train_data) / args.train_batch_size / args.gradient_accumulation_steps) * args.num_train_epochs\n","\n","# model\n","model = BertAbsSum(args.bert_model, decoder_config, device=device )\n","\n","#load state\n","\n","args.checkpoint = '/content/drive/My Drive/nlp/nlp_model/model_01-16-08:56:55/BertAbsSum_r72.bin'\n","if args.checkpoint:\n","  state_dict = torch.load(args.checkpoint)\n","  model.load_state_dict(state_dict)\n","\n","model.to(device)\n","\n","# optimizer\n","param_optimizer = list(model.named_parameters())\n","no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}]\n","optimizer = BertAdam(optimizer_grouped_parameters,\n","                     lr=args.learning_rate,\n","                     warmup=0.1,\n","                     t_total=num_train_optimization_steps)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["01/16/2020 11:54:21 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n","01/16/2020 11:54:21 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp6eh1sc0h\n","01/16/2020 11:54:24 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"WPYc6qiFit8b","colab_type":"text"},"source":["###Training"]},{"cell_type":"code","metadata":{"id":"mJ87xN9B2JyR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"03f5ccf9-ae82-4440-b8dd-fcb66d7f4f46","executionInfo":{"status":"ok","timestamp":1579001893034,"user_tz":-180,"elapsed":1081,"user":{"displayName":"Bukin Ruslan","photoUrl":"","userId":"02589038028886526730"}}},"source":[""],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["32.0"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"5QD9HwPe3DDv","colab_type":"code","outputId":"4e7a4df8-e9ad-4050-cc84-9fef65f51a7f","executionInfo":{"status":"ok","timestamp":1578858159822,"user_tz":-180,"elapsed":141334,"user":{"displayName":"","photoUrl":"","userId":""}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# training\n","\n","logger.info(\"***** Running training *****\")\n","logger.info(\"  Num examples = %d\", len(train_data))\n","logger.info(\"  Batch size = %d\", args.train_batch_size)\n","logger.info(\"  Num steps = %d\", num_train_optimization_steps)\n","model.train()\n","global_step = 0\n","for i in range(int(args.num_train_epochs)):\n","    # do training\n","    model.train()\n","    tr_loss = 0\n","    nb_tr_examples, nb_tr_steps = 0, 0\n","    for step, batch in enumerate(tqdm(train_dataloader, desc=\"Train iter\", position=0)):\n","        batch = tuple(t.to(device) for t in batch)\n","        logits = model(*batch)\n","        loss, _ = cal_performance(logits, batch[2])\n","\n","        if args.gradient_accumulation_steps > 1:\n","            loss = loss / args.gradient_accumulation_steps\n","        loss.backward()\n","        tr_loss += loss.item()\n","        nb_tr_examples += batch[0].size(0)\n","        nb_tr_steps += 1\n","        if (step + 1) % args.gradient_accumulation_steps == 0:\n","            optimizer.step()\n","            optimizer.zero_grad()\n","            global_step += 1\n","        if (step + 1) % args.print_every == 0:\n","            logger.info(f'Epoch {i}, step {step}, loss {loss.item()}.')\n","            logger.info(f'Ground: {\"\".join(tokenizer.convert_ids_to_tokens(batch[2][0].cpu().numpy()))}')\n","            logger.info(f'Generated: {\"\".join(tokenizer.convert_ids_to_tokens(logits[0].max(-1)[1].cpu().numpy()))}')\n","    \n","    #do save model\n","    if args.output_dir is not None:\n","        state_dict = model.state_dict()\n","        torch.save(state_dict, os.path.join(model_path, 'BertAbsSum_{}.bin'.format(i)))\n","        logger.info('Model saved')\n","    \n","    # do evaluation\n","    if valid_dataloader is not None:\n","        model.eval()\n","        batch = next(iter(valid_dataloader))\n","        batch = tuple(t.to(device) for t in batch)\n","        # beam_decode\n","        pred, _ = model.beam_decode(batch[0], batch[1], 3, 3)\n","        # pred = model.greedy_decode(batch[0], batch[1])\n","        logger.info(f'Source: {\"\".join(tokenizer.convert_ids_to_tokens(batch[0][0].cpu().numpy()))}')\n","        logger.info(f'Beam Generated: {\"\".join(tokenizer.convert_ids_to_tokens(pred[0][0]))}')\n","        # logger.info(f'Beam Generated: {tokenizer.convert_ids_to_tokens(pred[0].cpu().numpy())}')\n","    \n","    # do validate        \n","    do_validate()\n","\n","    logger.info(f'Epoch {i} finished.')\n","with open(os.path.join(args.bert_model, 'bert_config.json'), 'r') as f:\n","    bert_config = json.load(f)\n","config = {'bert_config': bert_config, 'decoder_config': decoder_config}\n","with open(os.path.join(model_path, 'config.json'), 'w') as f:\n","    json.dump(config, f)\n","logger.info('Training finished')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["01/16/2020 11:54:40 - INFO - __main__ -   ***** Running training *****\n","01/16/2020 11:54:40 - INFO - __main__ -     Num examples = 133621\n","01/16/2020 11:54:40 - INFO - __main__ -     Batch size = 16\n","01/16/2020 11:54:40 - INFO - __main__ -     Num steps = 1563\n","Train iter:   6%|▌         | 499/8351 [04:39<1:13:55,  1.77it/s]01/16/2020 11:59:20 - INFO - __main__ -   Epoch 0, step 499, loss 0.23252567648887634.\n","01/16/2020 11:59:20 - INFO - __main__ -   Ground: [CLS]conditionalgenerationofpath-en##tangledopticalnoonstates[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n","01/16/2020 11:59:20 - INFO - __main__ -   Generated: generation--path-en##tangledstatesstatesstatesfrom##sthethethethethethethethethethethethethethethethethethethethethethethethethethethethethethethethe\n","Train iter:  12%|█▏        | 999/8351 [09:18<1:07:53,  1.80it/s]01/16/2020 12:04:00 - INFO - __main__ -   Epoch 0, step 999, loss 0.2715405225753784.\n","01/16/2020 12:04:00 - INFO - __main__ -   Ground: [CLS]coe##xi##sten##ceofsocialnormsbasedonin-andout-groupinteractions[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n","01/16/2020 12:04:00 - INFO - __main__ -   Generated: coe##xi##stenof##cesocialsocialof-asocialbasedagentmodelbasedmodel[SEP][SEP]thethethethethethethethethethethethethethethethethethethethethethethethethethe\n","Train iter:  18%|█▊        | 1499/8351 [13:58<1:03:09,  1.81it/s]01/16/2020 12:08:39 - INFO - __main__ -   Epoch 0, step 1499, loss 0.23828892409801483.\n","01/16/2020 12:08:39 - INFO - __main__ -   Ground: [CLS]electron-ph##ono##ncouplinginatwo-dimensionalin##hom##ogen##eouselectrongas:consequencesforsurfacespectralproperties[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n","01/16/2020 12:08:39 - INFO - __main__ -   Generated: electron-ph##ono##onocouplingin##homin##ogenphelectron##hom##ogen##eouselectron##eous[SEP]aandelectronelectron-[SEP]electronthethethethethethethethethethethethethethethethethethethe\n","Train iter:  24%|██▍       | 1999/8351 [18:37<58:28,  1.81it/s]01/16/2020 12:13:19 - INFO - __main__ -   Epoch 0, step 1999, loss 0.2522174119949341.\n","01/16/2020 12:13:19 - INFO - __main__ -   Ground: [CLS]microscopicmodelsforlongrangedvol##ati##litycorrelation##s[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n","01/16/2020 12:13:19 - INFO - __main__ -   Generated: aofoflong-and##lity##lityin[SEP][SEP][SEP]thethethethethethethethethethethethethethethethethethethethethethethethethethethethethethethethe\n","Train iter:  30%|██▉       | 2499/8351 [23:17<55:01,  1.77it/s]01/16/2020 12:17:58 - INFO - __main__ -   Epoch 0, step 2499, loss 0.25814732909202576.\n","01/16/2020 12:17:58 - INFO - __main__ -   Ground: [CLS]ashorthistoryofmarko##vchainmontecarlo:subjectiverec##oll##ection##sfromincompletedata[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n","01/16/2020 12:17:58 - INFO - __main__ -   Generated: ahistoryofofmarko##vchainmonte[SEP][SEP]a,[SEP][SEP][SEP][SEP]the[SEP][SEP][SEP]thethethethethethethethethethethethethethethethethethethethethethethethe\n","Train iter:  36%|███▌      | 2999/8351 [27:56<49:31,  1.80it/s]01/16/2020 12:22:38 - INFO - __main__ -   Epoch 0, step 2999, loss 0.24554197490215302.\n","01/16/2020 12:22:38 - INFO - __main__ -   Ground: [CLS]log-con##ca##vitypropertyoftheerrorprobabilitywithapplicationtolocalboundsforwirelesscommunications[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n","01/16/2020 12:22:38 - INFO - __main__ -   Generated: log-con##ca##ca##vityforerrorerrorprobability[SEP]applicationsoferror##uss[SEP]thesystems[SEP][SEP]thethethethethethethethethethethethethethethethethethethethethethethethe\n","Train iter:  42%|████▏     | 3499/8351 [32:35<44:31,  1.82it/s]01/16/2020 12:27:17 - INFO - __main__ -   Epoch 0, step 3499, loss 0.2710959315299988.\n","01/16/2020 12:27:17 - INFO - __main__ -   Ground: [CLS]thetransitionfrombrown##ianmotiontoboom-and-bustdynamicsinfinancialandeconomicsystems[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n","01/16/2020 12:27:17 - INFO - __main__ -   Generated: thedynamics-dynamics--andthe-and-anddynamics[SEP]financialmarketsfinancialmarkets[SEP]marketsthethethethethethethethethethethethethethethethethethethethethethethethe\n","Train iter:  48%|████▊     | 3999/8351 [37:15<39:59,  1.81it/s]01/16/2020 12:31:56 - INFO - __main__ -   Epoch 0, step 3999, loss 0.26123151183128357.\n","01/16/2020 12:31:56 - INFO - __main__ -   Ground: [CLS]un##su##per##vis##edrankingofmulti-attributeobjectsbasedonprincipalcurves[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n","01/16/2020 12:31:56 - INFO - __main__ -   Generated: un##su##per##vis##edrankingformulti-attributedata[SEP]onmulticurves[SEP]curvesthethethethethethethethethethethethethethethethethethethethethethethethethethethe\n","Train iter:  54%|█████▍    | 4499/8351 [41:54<36:12,  1.77it/s]01/16/2020 12:36:36 - INFO - __main__ -   Epoch 0, step 4499, loss 0.2601125240325928.\n","01/16/2020 12:36:36 - INFO - __main__ -   Ground: [CLS]onthe2-pointfunctionoftheo(n)model[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n","01/16/2020 12:36:36 - INFO - __main__ -   Generated: thetheself-energy-intheself-n)[SEP][SEP]-thethethethethethethethethethethethethethethethethethethethethethethethethethethethethe\n","Train iter:  60%|█████▉    | 4999/8351 [46:34<30:59,  1.80it/s]01/16/2020 12:41:15 - INFO - __main__ -   Epoch 0, step 4999, loss 0.22806137800216675.\n","01/16/2020 12:41:15 - INFO - __main__ -   Ground: [CLS]improvedgraphlap##la##cianviageometricself-consistency[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n","01/16/2020 12:41:15 - INFO - __main__ -   Generated: graphgraphlaplap##cianandgraphgraph-lap[SEP][SEP]thethethethethethethethethethethethethethethethethethethethethethethethethethethethethethethethe\n","Train iter:  66%|██████▌   | 5499/8351 [51:13<26:12,  1.81it/s]01/16/2020 12:45:55 - INFO - __main__ -   Epoch 0, step 5499, loss 0.2543146312236786.\n","01/16/2020 12:45:55 - INFO - __main__ -   Ground: [CLS]sep##sisisasyndromewithhyper##act##ivityofth##17-likeinnateimmunityandh##yp##oa##ct##ivityofadaptiveimmunity[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n","01/16/2020 12:45:55 - INFO - __main__ -   Generated: hyper##act##act##acthyperofhyper##act##act##ivityth##munimmunitylikeimmunity[SEP][SEP]himmunityimmunity[SEP][SEP][SEP]immunityimmunity[SEP][SEP]thethethethethethethethethethethethethethethethethe\n","Train iter:  72%|███████▏  | 5999/8351 [55:53<21:39,  1.81it/s]01/16/2020 12:50:34 - INFO - __main__ -   Epoch 0, step 5999, loss 0.2660982012748718.\n","01/16/2020 12:50:34 - INFO - __main__ -   Ground: [CLS]learningfastmagneticresonanceimaging[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n","01/16/2020 12:50:34 - INFO - __main__ -   Generated: learningacceleratedacceleratedmrreconstructionforreconstructionthethethethethethethethethethethethethethethethethethethethethethethethethethethethethethethethethethethethethe\n","Train iter:  78%|███████▊  | 6499/8351 [1:00:32<17:22,  1.78it/s]01/16/2020 12:55:14 - INFO - __main__ -   Epoch 0, step 6499, loss 0.24786978960037231.\n","01/16/2020 12:55:14 - INFO - __main__ -   Ground: [CLS]entropy-assistedmulti-mod##alemotionrecognitionframeworkbasedonphysiologicalsignals[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n","01/16/2020 12:55:14 - INFO - __main__ -   Generated: entropy-scalemulti-domainemotionemotionrecognitionforforemotionemotionrecognition[SEP]recognitionthethethethethethethethethethethethethethethethethethethethethethethethethethethethe\n","Train iter:  84%|████████▍ | 6999/8351 [1:05:12<12:27,  1.81it/s]01/16/2020 12:59:53 - INFO - __main__ -   Epoch 0, step 6999, loss 0.2794264554977417.\n","01/16/2020 12:59:53 - INFO - __main__ -   Ground: [CLS]jointlanguageidentificationofcode-switchingspeechusingattentionbasede##2##enetwork[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n","01/16/2020 12:59:53 - INFO - __main__ -   Generated: a-systemsystemcode-switchingspeech-the----[SEP][SEP][SEP]thethethethethethethethethethethethethethethethethethethethethethethethethethethe\n","Train iter:  90%|████████▉ | 7499/8351 [1:09:51<07:49,  1.81it/s]01/16/2020 13:04:32 - INFO - __main__ -   Epoch 0, step 7499, loss 0.24171477556228638.\n","01/16/2020 13:04:32 - INFO - __main__ -   Ground: [CLS]hiddenpopulationsizeestimationfromrespond##ent-drivensampling:anetworkapproach[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n","01/16/2020 13:04:32 - INFO - __main__ -   Generated: estpopulationpopulation:usingrespond##ent-drivensampling[SEP]anetworkapproach[SEP]methodthethethethethethethethethethethethethethethethethethethethethethethethethethethethe\n","Train iter:  96%|█████████▌| 7999/8351 [1:14:30<03:14,  1.81it/s]01/16/2020 13:09:12 - INFO - __main__ -   Epoch 0, step 7999, loss 0.2437782883644104.\n","01/16/2020 13:09:12 - INFO - __main__ -   Ground: [CLS]mappingclassgroupshavefiniteas##ym##pt##oticdimension[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n","01/16/2020 13:09:12 - INFO - __main__ -   Generated: mappingclassofofofgroups##ym##pt##oticdimensionofgroupsthethethethethethethethethethethethethethethethethethethethethethethethethethethethethethethethe\n","Train iter: 100%|██████████| 8351/8351 [1:17:47<00:00,  1.81it/s]\n","01/16/2020 13:12:31 - INFO - __main__ -   Model saved\n","01/16/2020 13:12:32 - INFO - __main__ -   Source: [CLS]atransformationgroupapproachtothepriorfortheparametersofthebetadistributionissuggestedwhichaccountsforfinitesetsofdatabyimposingalimittotherangeofparametervaluesunderconsideration.therelationshipbetweenthebetadistributionandthepo##issonandgammadistributionsinthecontinuumisexplored,withanemphasisonthedecompositionofthemodelintoseparateestimatesforsizeandshape.useofthebetadistributioninclassificationandpredictionproblemsisdiscussed,andtheeffectofthepriorontheanalysisofsomewellknownexamplesfromstatisticalgeneticsisexamined.[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n","01/16/2020 13:12:32 - INFO - __main__ -   Beam Generated: atransformationgroupapproachtothebetadistribution[SEP]\n","01/16/2020 13:12:32 - INFO - __main__ -   ***** Running validation *****\n","Val iter: 100%|██████████| 86/86 [02:10<00:00,  1.53s/it]\n","01/16/2020 13:14:43 - INFO - __main__ -   ******Validation results******\n","01/16/2020 13:14:43 - INFO - __main__ -   Rouge-1: 0.7070529265016423\n","01/16/2020 13:14:43 - INFO - __main__ -   Rouge-2: 0.5759076698430247\n","01/16/2020 13:14:43 - INFO - __main__ -   Validation finished.\n","01/16/2020 13:14:43 - INFO - __main__ -   Epoch 0 finished.\n","Train iter:   6%|▌         | 499/8351 [04:39<1:13:42,  1.78it/s]01/16/2020 13:19:22 - INFO - __main__ -   Epoch 1, step 499, loss 0.2421770840883255.\n","01/16/2020 13:19:22 - INFO - __main__ -   Ground: [CLS]neural(ee##g)responseduringcreationandappreciation:anovelstudywithhindus##tanirag##amusic[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n","01/16/2020 13:19:22 - INFO - __main__ -   Generated: abraineeof##s##sinmusicmusicmusicmusicastudystudyofa##gmusic[SEP][SEP][SEP]musicthethethethethethethethethethethethethethethethethethethethethethe\n","Train iter:  12%|█▏        | 999/8351 [09:18<1:08:00,  1.80it/s]01/16/2020 13:24:02 - INFO - __main__ -   Epoch 1, step 999, loss 0.25031110644340515.\n","01/16/2020 13:24:02 - INFO - __main__ -   Ground: [CLS]suppressionofvortexchannel##inginmean##der##edy##ba##2##cu##3##o##7-dgrainboundaries[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n","01/16/2020 13:24:02 - INFO - __main__ -   Generated: criticalchannelcurrentdensitydensityinmean##ar##arand##2##cu##o##o##3[SEP][SEP]d##3##o[SEP][SEP]thethethethethethethethethethethethethethethethethethethethethethe\n","Train iter:  18%|█▊        | 1499/8351 [13:57<1:02:59,  1.81it/s]01/16/2020 13:28:41 - INFO - __main__ -   Epoch 1, step 1499, loss 0.22474771738052368.\n","01/16/2020 13:28:41 - INFO - __main__ -   Ground: [CLS]hilbert'sfourteenthproblemoverfinitefields,andaconjectureontheconeofcurves[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n","01/16/2020 13:28:41 - INFO - __main__ -   Generated: the-sconjectureconjectureandthefields[SEP]andellipticconjectureofdimensionfinite[SEP]rank[SEP]rankthethethethethethethethethethethethethethethethethethethethethethethethethe\n","Train iter:  24%|██▍       | 1999/8351 [18:37<58:40,  1.80it/s]01/16/2020 13:33:21 - INFO - __main__ -   Epoch 1, step 1999, loss 0.2275676429271698.\n","01/16/2020 13:33:21 - INFO - __main__ -   Ground: [CLS]non-convexglobalmini##mi##zationandfalsediscoveryratecontrolforthetre##x[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n","01/16/2020 13:33:21 - INFO - __main__ -   Generated: a-convexconvexoptimization##mi##zationforthe##zationfor##zationforthetre##mi##zationthethethethethethethethethethethethethethethethethethethethethethethethethethethe\n","Train iter:  30%|██▉       | 2499/8351 [23:17<54:57,  1.77it/s]01/16/2020 13:38:00 - INFO - __main__ -   Epoch 1, step 2499, loss 0.26591962575912476.\n","01/16/2020 13:38:00 - INFO - __main__ -   Ground: [CLS]imagingtime-seriestoimproveclassificationandimp##utation[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n","01/16/2020 13:38:00 - INFO - __main__ -   Generated: encodingtimeseriesbasedclassificationtimetimeandimp##utation##utation[SEP]thethethethethethethethethethethethethethethethethethethethethethethethethethethethethethethethe\n","Train iter:  36%|███▌      | 2999/8351 [27:56<49:29,  1.80it/s]01/16/2020 13:42:40 - INFO - __main__ -   Epoch 1, step 2999, loss 0.23568420112133026.\n","01/16/2020 13:42:40 - INFO - __main__ -   Ground: [CLS]towardsnon##station##ary,non##para##metricindependentprocessanalysiswithunknownsourcecomponentdimensions[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n","01/16/2020 13:42:40 - INFO - __main__ -   Generated: independentnon##para##ssiprocessnon##para##metricprocess##ssianalysiswithunknownsourcecomponentcomponent[SEP]componentthethethethethethethethethethethethethethethethethethethethethethethethethethe\n","Train iter:  42%|████▏     | 3499/8351 [32:36<44:35,  1.81it/s]01/16/2020 13:47:19 - INFO - __main__ -   Epoch 1, step 3499, loss 0.2278127670288086.\n","01/16/2020 13:47:19 - INFO - __main__ -   Ground: [CLS]onacharacterizationoforderedpivotalsampling[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n","01/16/2020 13:47:19 - INFO - __main__ -   Generated: characterizationcharacterizationcharacterizationoforderedsamplingsampling[SEP]onthethethethethethethethethethethethethethethethethethethethethethethethethethethethethethethethethethethe\n","Train iter:  46%|████▌     | 3817/8351 [35:33<41:52,  1.80it/s]"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"WL3gA01uHlar","colab_type":"code","colab":{}},"source":["#!ls /content/bertsum/output/model_01-13-05:43:53 -la\n","#!cp /content/bertsum/output/model_01-13-05:43:53/BertAbsSum_1.bin /content/drive/My\\ Drive/nlp/BertAbsSum_11.bin\n","# !cp /content/bertsum/output/model_01-13-05:43:53/config.json /content/drive/My\\ Drive/nlp"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-CADWqILgRlb","colab_type":"code","colab":{}},"source":["# do_validate()\n","107975 \n","65428 42547 42076 \n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xHNngTAigSk9","colab_type":"text"},"source":["##Validate"]},{"cell_type":"code","metadata":{"id":"ZAM_OuvejGqY","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FzXzlhLAgyQg","colab_type":"code","colab":{}},"source":["class ARGS(object):\n","    # data_dir = 'data/processed_data'\n","    bert_model = 'bert-base-uncased'\n","    output_dir = 'output'\n","    model_path =  'output/model_01-13-05:43:53/BertAbsSum_1.bin'\n","    config_path = 'output/model_01-13-05:43:53/config.json'\n","    result_path = 'result'\n","    batch_size = 16\n","    max_src_len = 130\n","    \n","    # GPU_index = 0\n","    # learning_rate = 5e-5\n","    # num_train_epochs = 3\n","    # warmup_proportion = 0.1\n","    # max_src_len = 130\n","    # max_tgt_len = 30\n","    # train_batch_size = 16\n","    # decoder_config = None\n","    # print_every = 100\n","    # gradient_accumulation_steps = 1\n","\n","\n","args = ARGS()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jj8Ez_N4n3u7","colab_type":"code","colab":{}},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","with open(args.config_path, 'r') as f:\n","    config = json.load(f)\n","\n","model = BertAbsSum(args.bert_model, config['decoder_config'], device)\n","model.load_state_dict(torch.load(args.model_path))\n","model.to(device)\n","\n","# processor = CSVProcessor()\n","# tokenizer = BertTokenizer.from_pretrained(args.bert_model)\n","# tokenizer = BertTokenizer.from_pretrained(os.path.join(args.bert_model, 'vocab.txt'))\n","\n","# test_examples = processor.get_test_examples(args.valid_path)\n","# test_features = convert_examples_to_features(test_examples, args.max_src_len, args.max_tgt_len, tokenizer)\n","# test_data = create_dataset(test_features)\n","# test_sampler = RandomSampler(test_data)\n","# test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=BATCH_SIZE, drop_last=True)\n","# logger.info('Loading complete. Writing results to %s' % (args.result_path))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pUtdOFTIgRi3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":402},"outputId":"8f66da5d-5cb2-42ff-d25f-ecb572c3fb3d","executionInfo":{"status":"error","timestamp":1578915880019,"user_tz":-180,"elapsed":6369,"user":{"displayName":"Bukin Ruslan","photoUrl":"","userId":"02589038028886526730"}}},"source":[""],"execution_count":33,"outputs":[{"output_type":"stream","text":["Iteration:   0%|          | 4/838 [00:05<18:44,  1.35s/it]"],"name":"stderr"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-33-e2559f5cf085>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Iteration\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeam_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/bertsum/model.py\u001b[0m in \u001b[0;36mbeam_decode\u001b[0;34m(self, src_seq, src_mask, beam_size, n_best)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m                 active_inst_idx_list = beam_decode_step(\n\u001b[0;32m--> 201\u001b[0;31m                     inst_dec_beams, len_dec_seq, src_seq, src_enc, inst_idx_to_position_map, beam_size)\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mactive_inst_idx_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/bertsum/model.py\u001b[0m in \u001b[0;36mbeam_decode_step\u001b[0;34m(inst_dec_beams, len_dec_seq, src_seq, enc_output, inst_idx_to_position_map, beam_size)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0mdec_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_beam_dec_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst_dec_beams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen_dec_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mword_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_active_inst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;31m# Update the beam with predicted word prob information and collect incomplete instances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/bertsum/model.py\u001b[0m in \u001b[0;36mpredict_word\u001b[0;34m(dec_seq, src_seq, enc_output, n_active_inst, beam_size)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mpredict_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_active_inst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                 \u001b[0mdec_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m                 \u001b[0mdec_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdec_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Pick the last step: (bh * bm) * d_h\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0mword_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/bertsum/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tgt_seq, src_seq, enc_output)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mdec_enc_attn_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_attn_key_pad_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_q\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtgt_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mtgt_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;31m# -- Forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mdec_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_seq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_enc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"YlMFUL-HtJuR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"db9da36d-812c-4d78-ce87-0e02783a696c","executionInfo":{"status":"ok","timestamp":1578915846622,"user_tz":-180,"elapsed":854,"user":{"displayName":"Bukin Ruslan","photoUrl":"","userId":"02589038028886526730"}}},"source":[""],"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.6798116839783025"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"Hpn-Cj9ms3hf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"ea8ba79a-01b2-4187-c09a-b6d7a9859856","executionInfo":{"status":"ok","timestamp":1578915588345,"user_tz":-180,"elapsed":851,"user":{"displayName":"Bukin Ruslan","photoUrl":"","userId":"02589038028886526730"}}},"source":["print(len(hyp_list), len(ref_list))"],"execution_count":25,"outputs":[{"output_type":"stream","text":["13408 13408\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7M85q_0yll7_","colab_type":"text"},"source":["##Predict"]},{"cell_type":"markdown","metadata":{"id":"Q3rb1QF9mMrB","colab_type":"text"},"source":["###Load model"]},{"cell_type":"code","metadata":{"id":"Nvn5wKk-mFlO","colab_type":"code","colab":{}},"source":["class ARGS(object):\n","    # data_dir = 'data/processed_data'\n","    bert_model = 'bert-base-uncased'\n","    output_dir = 'output'\n","    model_path =  '/content/drive/My Drive/nlp/nlp_model/model_01-16-08:56:55/BertAbsSum_r72.bin'\n","    config_path = '/content/drive/My Drive/nlp/nlp_model/model_01-16-04:21:20/config.json'\n","    result_path = 'result'\n","    batch_size = 16\n","    max_src_len = 512\n","args = ARGS    \n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-W46pBZXuX6u","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"df21466e-d532-40b4-dd12-281665db15bf","executionInfo":{"status":"ok","timestamp":1579175087916,"user_tz":-180,"elapsed":14374,"user":{"displayName":"Bukin Ruslan","photoUrl":"","userId":"02589038028886526730"}}},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","with open(args.config_path, 'r') as f:\n","    config = json.load(f)\n","\n","model = BertAbsSum(args.bert_model, config['decoder_config'], device)\n","model.load_state_dict(torch.load(args.model_path))\n","model.to(device)\n"],"execution_count":55,"outputs":[{"output_type":"stream","text":["01/16/2020 11:44:34 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n","01/16/2020 11:44:34 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpwxj3vlew\n","01/16/2020 11:44:37 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["BertAbsSum(\n","  (bert_encoder): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768, padding_idx=0)\n","      (token_type_embeddings): Embedding(2, 768, padding_idx=0)\n","      (LayerNorm): BertLayerNorm()\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): BertLayerNorm()\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (bert_emb): BertEmbeddings(\n","    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","    (position_embeddings): Embedding(512, 768, padding_idx=0)\n","    (token_type_embeddings): Embedding(2, 768, padding_idx=0)\n","    (LayerNorm): BertLayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (decoder): BertDecoder(\n","    (position_enc): Embedding(46, 768)\n","    (embedding): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768, padding_idx=0)\n","      (token_type_embeddings): Embedding(2, 768, padding_idx=0)\n","      (LayerNorm): BertLayerNorm()\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (layer_stack): ModuleList(\n","      (0): DecoderLayer(\n","        (slf_attn): MultiHeadAttention(\n","          (w_qs): Linear(in_features=768, out_features=768, bias=True)\n","          (w_ks): Linear(in_features=768, out_features=768, bias=True)\n","          (w_vs): Linear(in_features=768, out_features=768, bias=True)\n","          (attention): ScaledDotProductAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (softmax): Softmax(dim=2)\n","          )\n","          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc): Linear(in_features=768, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (enc_attn): MultiHeadAttention(\n","          (w_qs): Linear(in_features=768, out_features=768, bias=True)\n","          (w_ks): Linear(in_features=768, out_features=768, bias=True)\n","          (w_vs): Linear(in_features=768, out_features=768, bias=True)\n","          (attention): ScaledDotProductAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (softmax): Softmax(dim=2)\n","          )\n","          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc): Linear(in_features=768, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (pos_ffn): PositionwiseFeedForward(\n","          (w_1): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n","          (w_2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n","          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (1): DecoderLayer(\n","        (slf_attn): MultiHeadAttention(\n","          (w_qs): Linear(in_features=768, out_features=768, bias=True)\n","          (w_ks): Linear(in_features=768, out_features=768, bias=True)\n","          (w_vs): Linear(in_features=768, out_features=768, bias=True)\n","          (attention): ScaledDotProductAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (softmax): Softmax(dim=2)\n","          )\n","          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc): Linear(in_features=768, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (enc_attn): MultiHeadAttention(\n","          (w_qs): Linear(in_features=768, out_features=768, bias=True)\n","          (w_ks): Linear(in_features=768, out_features=768, bias=True)\n","          (w_vs): Linear(in_features=768, out_features=768, bias=True)\n","          (attention): ScaledDotProductAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (softmax): Softmax(dim=2)\n","          )\n","          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc): Linear(in_features=768, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (pos_ffn): PositionwiseFeedForward(\n","          (w_1): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n","          (w_2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n","          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (2): DecoderLayer(\n","        (slf_attn): MultiHeadAttention(\n","          (w_qs): Linear(in_features=768, out_features=768, bias=True)\n","          (w_ks): Linear(in_features=768, out_features=768, bias=True)\n","          (w_vs): Linear(in_features=768, out_features=768, bias=True)\n","          (attention): ScaledDotProductAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (softmax): Softmax(dim=2)\n","          )\n","          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc): Linear(in_features=768, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (enc_attn): MultiHeadAttention(\n","          (w_qs): Linear(in_features=768, out_features=768, bias=True)\n","          (w_ks): Linear(in_features=768, out_features=768, bias=True)\n","          (w_vs): Linear(in_features=768, out_features=768, bias=True)\n","          (attention): ScaledDotProductAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (softmax): Softmax(dim=2)\n","          )\n","          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc): Linear(in_features=768, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (pos_ffn): PositionwiseFeedForward(\n","          (w_1): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n","          (w_2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n","          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (3): DecoderLayer(\n","        (slf_attn): MultiHeadAttention(\n","          (w_qs): Linear(in_features=768, out_features=768, bias=True)\n","          (w_ks): Linear(in_features=768, out_features=768, bias=True)\n","          (w_vs): Linear(in_features=768, out_features=768, bias=True)\n","          (attention): ScaledDotProductAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (softmax): Softmax(dim=2)\n","          )\n","          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc): Linear(in_features=768, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (enc_attn): MultiHeadAttention(\n","          (w_qs): Linear(in_features=768, out_features=768, bias=True)\n","          (w_ks): Linear(in_features=768, out_features=768, bias=True)\n","          (w_vs): Linear(in_features=768, out_features=768, bias=True)\n","          (attention): ScaledDotProductAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (softmax): Softmax(dim=2)\n","          )\n","          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc): Linear(in_features=768, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (pos_ffn): PositionwiseFeedForward(\n","          (w_1): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n","          (w_2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n","          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (4): DecoderLayer(\n","        (slf_attn): MultiHeadAttention(\n","          (w_qs): Linear(in_features=768, out_features=768, bias=True)\n","          (w_ks): Linear(in_features=768, out_features=768, bias=True)\n","          (w_vs): Linear(in_features=768, out_features=768, bias=True)\n","          (attention): ScaledDotProductAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (softmax): Softmax(dim=2)\n","          )\n","          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc): Linear(in_features=768, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (enc_attn): MultiHeadAttention(\n","          (w_qs): Linear(in_features=768, out_features=768, bias=True)\n","          (w_ks): Linear(in_features=768, out_features=768, bias=True)\n","          (w_vs): Linear(in_features=768, out_features=768, bias=True)\n","          (attention): ScaledDotProductAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (softmax): Softmax(dim=2)\n","          )\n","          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc): Linear(in_features=768, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (pos_ffn): PositionwiseFeedForward(\n","          (w_1): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n","          (w_2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n","          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (5): DecoderLayer(\n","        (slf_attn): MultiHeadAttention(\n","          (w_qs): Linear(in_features=768, out_features=768, bias=True)\n","          (w_ks): Linear(in_features=768, out_features=768, bias=True)\n","          (w_vs): Linear(in_features=768, out_features=768, bias=True)\n","          (attention): ScaledDotProductAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (softmax): Softmax(dim=2)\n","          )\n","          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc): Linear(in_features=768, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (enc_attn): MultiHeadAttention(\n","          (w_qs): Linear(in_features=768, out_features=768, bias=True)\n","          (w_ks): Linear(in_features=768, out_features=768, bias=True)\n","          (w_vs): Linear(in_features=768, out_features=768, bias=True)\n","          (attention): ScaledDotProductAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (softmax): Softmax(dim=2)\n","          )\n","          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc): Linear(in_features=768, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (pos_ffn): PositionwiseFeedForward(\n","          (w_1): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n","          (w_2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n","          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (6): DecoderLayer(\n","        (slf_attn): MultiHeadAttention(\n","          (w_qs): Linear(in_features=768, out_features=768, bias=True)\n","          (w_ks): Linear(in_features=768, out_features=768, bias=True)\n","          (w_vs): Linear(in_features=768, out_features=768, bias=True)\n","          (attention): ScaledDotProductAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (softmax): Softmax(dim=2)\n","          )\n","          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc): Linear(in_features=768, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (enc_attn): MultiHeadAttention(\n","          (w_qs): Linear(in_features=768, out_features=768, bias=True)\n","          (w_ks): Linear(in_features=768, out_features=768, bias=True)\n","          (w_vs): Linear(in_features=768, out_features=768, bias=True)\n","          (attention): ScaledDotProductAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (softmax): Softmax(dim=2)\n","          )\n","          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc): Linear(in_features=768, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (pos_ffn): PositionwiseFeedForward(\n","          (w_1): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n","          (w_2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n","          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (7): DecoderLayer(\n","        (slf_attn): MultiHeadAttention(\n","          (w_qs): Linear(in_features=768, out_features=768, bias=True)\n","          (w_ks): Linear(in_features=768, out_features=768, bias=True)\n","          (w_vs): Linear(in_features=768, out_features=768, bias=True)\n","          (attention): ScaledDotProductAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (softmax): Softmax(dim=2)\n","          )\n","          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc): Linear(in_features=768, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (enc_attn): MultiHeadAttention(\n","          (w_qs): Linear(in_features=768, out_features=768, bias=True)\n","          (w_ks): Linear(in_features=768, out_features=768, bias=True)\n","          (w_vs): Linear(in_features=768, out_features=768, bias=True)\n","          (attention): ScaledDotProductAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (softmax): Softmax(dim=2)\n","          )\n","          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc): Linear(in_features=768, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (pos_ffn): PositionwiseFeedForward(\n","          (w_1): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n","          (w_2): Conv1d(768, 768, kernel_size=(1,), stride=(1,))\n","          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (last_linear): Linear(in_features=768, out_features=30522, bias=True)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":55}]},{"cell_type":"code","metadata":{"id":"ev2Xjl76nmSn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":140},"outputId":"b7d92d6d-0efd-483d-82cc-a7d1bb737655","executionInfo":{"status":"ok","timestamp":1579149166773,"user_tz":-180,"elapsed":3311,"user":{"displayName":"Bukin Ruslan","photoUrl":"","userId":"02589038028886526730"}}},"source":[""],"execution_count":25,"outputs":[{"output_type":"stream","text":["BertAbsSum.ipynb   predict.sh\t\t      server.sh\n","bert-base-uncased  preprocess.py\t      train.csv.zip\n","data\t\t   __pycache__\t\t      train.py\n","data.py\t\t   pytorch_pretrained_bert    train.sh\n","distilmodel.py\t   readme.md\t\t      transformer\n","model.py\t   sample_submission.csv.zip  utils.py\n","predict.py\t   server.py\t\t      vocs.pkl.zip\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Gio6mNTmmQR-","colab_type":"text"},"source":["###Generate titles"]},{"cell_type":"code","metadata":{"id":"n9Bti4I4ljz5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"6995c4a3-e269-4fb3-9576-90ea820ada25","executionInfo":{"status":"ok","timestamp":1579175331339,"user_tz":-180,"elapsed":248270,"user":{"displayName":"Bukin Ruslan","photoUrl":"","userId":"02589038028886526730"}}},"source":["\n","import pandas as pd\n","from tqdm import tqdm\n","test = pd.read_csv('data/test.csv', encoding='utf8')\n","\n","titles = []\n","\n","for row in tqdm(test.iterrows(), desc=\"Predict iteration\", total = test.shape[0], position=0):\n","  i, text = row\n","  src, src_mask = convert_one_example(text[0], args.max_src_len, tokenizer)\n","  pred, _ = model.beam_decode(src.to(device), src_mask.to(device), 3, 3)  \n","  # print(\" \".join(tokenizer.convert_ids_to_tokens(pred[0][0])).split('[SEP]')[0])\n","\n","  # De-tokenize.\n","  tok_text = \" \".join(tokenizer.convert_ids_to_tokens(pred[0][0])).split('[SEP]')[0]\n","  tok_text = tok_text.replace(\" ##\", \"\")\n","  tok_text = tok_text.replace(\"##\", \"\")  \n","  \n","  # tok_text = ''\n","  # for t in tokenizer.convert_ids_to_tokens(pred[0][0]):\n","  #   tok_text += ' ' + t if not t.startswith('##') else t[2:]\n","  # tok_text = tok_text.split('[SEP]')[0][1:]\n","  titles.append(tok_text)"],"execution_count":56,"outputs":[{"output_type":"stream","text":["Predict iteration: 100%|██████████| 1000/1000 [04:03<00:00,  4.71it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"DUli0ZLWljxk","colab_type":"code","colab":{}},"source":["submission_df = pd.DataFrame({'abstract': test.abstract, 'title': titles})\n","submission_df.to_csv('predicted_titles.csv', index=False)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AVgoREBHmV5L","colab_type":"text"},"source":["###Submission"]},{"cell_type":"code","metadata":{"id":"MhR5PhD9l1Hr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"outputId":"349220fe-8c27-485c-ad86-154dfa2185d6","executionInfo":{"status":"ok","timestamp":1579175333871,"user_tz":-180,"elapsed":1577,"user":{"displayName":"Bukin Ruslan","photoUrl":"","userId":"02589038028886526730"}}},"source":["import string\n","from nltk.util import ngrams\n","import numpy as np\n","import pandas as pd\n","import pickle\n","\n","def generate_csv(input_file='predicted_titles.csv',\n","                 output_file='submission.csv',\n","                 voc_file='data/vocs.pkl'):\n","    '''\n","    Generates file in format required for submitting result to Kaggle\n","    \n","    Parameters:\n","        input_file (str) : path to csv file with your predicted titles.\n","                           Should have two fields: abstract and title\n","        output_file (str) : path to output submission file\n","        voc_file (str) : path to voc.pkl file\n","    '''\n","    data = pd.read_csv(input_file)\n","    with open(voc_file, 'rb') as voc_file:\n","        vocs = pickle.load(voc_file)\n","\n","    with open(output_file, 'w') as res_file:\n","        res_file.write('Id,Predict\\n')\n","        \n","    output_idx = 0\n","    for row_idx, row in data.iterrows():\n","        trg = row['title']\n","        trg = trg.translate(str.maketrans('', '', string.punctuation)).lower().split()\n","        trg.extend(['_'.join(ngram) for ngram in list(ngrams(trg, 2)) + list(ngrams(trg, 3))])\n","        \n","        VOCAB_stoi = vocs[row_idx]\n","        trg_intersection = set(VOCAB_stoi.keys()).intersection(set(trg))\n","        trg_vec = np.zeros(len(VOCAB_stoi))    \n","\n","        for word in trg_intersection:\n","            trg_vec[VOCAB_stoi[word]] = 1\n","\n","        with open(output_file, 'a') as res_file:\n","            for is_word in trg_vec:\n","                res_file.write('{0},{1}\\n'.format(output_idx, int(is_word)))\n","                output_idx += 1\n","\n","\n","generate_csv()"],"execution_count":58,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: DeprecationWarning: generator 'ngrams' raised StopIteration\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"YHHG7mRcl1OO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":70},"outputId":"54bd417c-675c-4113-8b34-7e7b9521d5ed","executionInfo":{"status":"ok","timestamp":1579175375329,"user_tz":-180,"elapsed":9252,"user":{"displayName":"Bukin Ruslan","photoUrl":"","userId":"02589038028886526730"}}},"source":["#.26  !kaggle competitions submit -c title-generation -m \"256x45 BertAbsSum_r67.bin\" -f submission.csv \n","#.32  !kaggle competitions submit -c title-generation -m \"256x45 BertAbsSum_r71.bin\" -f submission.csv \n","#.345 !kaggle competitions submit -c title-generation -m \"256x45 BertAbsSum_r72.bin\" -f submission.csv "],"execution_count":60,"outputs":[{"output_type":"stream","text":["Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n","100% 2.84M/2.84M [00:04<00:00, 599kB/s]\n","Successfully submitted to Arxiv Title Generation"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lIF7JirNl1Ld","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":492},"outputId":"4647367c-eb84-454b-f7ee-3c09fb7e2557","executionInfo":{"status":"ok","timestamp":1579175357361,"user_tz":-180,"elapsed":4471,"user":{"displayName":"Bukin Ruslan","photoUrl":"","userId":"02589038028886526730"}}},"source":["!ls -la"],"execution_count":59,"outputs":[{"output_type":"stream","text":["total 56104\n","drwxr-xr-x 8 root root     4096 Jan 16 04:38 .\n","drwxr-xr-x 1 root root     4096 Jan 16 04:20 ..\n","-rw-r--r-- 1 root root     8444 Jan 16 04:20 BertAbsSum.ipynb\n","drwxr-xr-x 2 root root     4096 Jan 16 04:20 bert-base-uncased\n","drwxr-xr-x 2 root root     4096 Jan 16 04:22 data\n","-rw-r--r-- 1 root root      563 Jan 16 04:20 data.py\n","-rw-r--r-- 1 root root    10304 Jan 16 04:20 distilmodel.py\n","drwxr-xr-x 8 root root     4096 Jan 16 04:20 .git\n","-rw-r--r-- 1 root root    10286 Jan 16 04:20 model.py\n","-rw-r--r-- 1 root root   986667 Jan 16 11:48 predicted_titles.csv\n","-rw-r--r-- 1 root root     4933 Jan 16 04:20 predict.py\n","-rw-r--r-- 1 root root      279 Jan 16 04:20 predict.sh\n","-rw-r--r-- 1 root root     8665 Jan 16 04:20 preprocess.py\n","drwxr-xr-x 2 root root     4096 Jan 16 04:21 __pycache__\n","drwxr-xr-x 3 root root     4096 Jan 16 04:21 pytorch_pretrained_bert\n","-rw-r--r-- 1 root root     3232 Jan 16 04:20 readme.md\n","-rw-r--r-- 1 root root   796278 Jan 16 04:22 sample_submission.csv.zip\n","-rw-r--r-- 1 root root     3322 Jan 16 04:20 server.py\n","-rw-r--r-- 1 root root      206 Jan 16 04:20 server.sh\n","-rw-r--r-- 1 root root  2979879 Jan 16 11:48 submission.csv\n","-rw-r--r-- 1 root root 45846731 Jan 16 04:22 train.csv.zip\n","-rw-r--r-- 1 root root    13226 Jan 16 04:20 train.py\n","-rw-r--r-- 1 root root      218 Jan 16 04:20 train.sh\n","drwxr-xr-x 3 root root     4096 Jan 16 04:21 transformer\n","-rw-r--r-- 1 root root     1352 Jan 16 04:20 utils.py\n","-rw-r--r-- 1 root root  6696617 Jan 16 04:22 vocs.pkl.zip\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WjVt5fNxmcUp","colab_type":"text"},"source":["#Trash"]},{"cell_type":"code","metadata":{"id":"fZS3pEsLljtm","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2l-ynDMcvOlD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":238},"outputId":"e8d0b5b8-08a7-4518-d83a-be47eb21fb33","executionInfo":{"status":"error","timestamp":1578916325504,"user_tz":-180,"elapsed":865,"user":{"displayName":"Bukin Ruslan","photoUrl":"","userId":"02589038028886526730"}}},"source":["test_examples = processor.get_test_examples('../data/test.csv')\n","\n","test_features = convert_examples_to_features(test_examples, args.max_src_len, args.max_tgt_len, tokenizer)\n","test_data = create_dataset(test_features)\n","test_sampler = RandomSampler(test_data)\n","test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=args.batch_size, drop_last=True)\n","logger.info('Loading test data complete.')\n","\n","\n","#test_dataloader"],"execution_count":36,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-36-d60b8b9544ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_test_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtest_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_examples_to_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_src_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_tgt_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_sampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'ARGS' object has no attribute 'max_src_len'"]}]},{"cell_type":"code","metadata":{"id":"3eaL_85SvK9F","colab_type":"code","colab":{}},"source":["for batch in tqdm(test_dataloader, desc=\"Iteration\", position=0):\n","    batch = tuple(t.to(device) for t in batch)\n","    pred, _ = model.beam_decode(batch[0], batch[1], 3, 3)\n","    src, tgt = batch[0], batch[2]\n","    for i in range(args.batch_size):\n","        sample_src = \"\".join(tokenizer.convert_ids_to_tokens(src[i].cpu().numpy())).split('[CLS]')[1].split('[SEP]')[0] + '\\n'\n","        sample_tgt = \"\".join(tokenizer.convert_ids_to_tokens(tgt[i].cpu().numpy())).split('[CLS]')[1].split('[SEP]')[0] + '\\n'\n","        sample_pred = \"\".join(tokenizer.convert_ids_to_tokens(pred[i][0])).split('[SEP]')[0] + '\\n'\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"13eh_d6k0r4P","colab_type":"code","colab":{}},"source":["import string\n","from nltk.util import ngrams\n","import numpy as np\n","import pandas as pd\n","import pickle\n","\n","with open('../data/vocs.pkl', 'rb') as voc_file:\n","    vocs = pickle.load(voc_file)\n","\n","\n","output_idx = 0\n","for row_idx, text in test[:10].iterrows():\n","  \n","  src, src_mask = convert_one_example(text[0], args.max_src_len, tokenizer)\n","  pred, _ = model.beam_decode(src.to(device), src_mask.to(device), 3, 3)\n","  trg = \"\".join(tokenizer.convert_ids_to_tokens(pred[0][0])).split('[SEP]')[0]\n","  # trg = row['title']\n","  print(trg)\n","  trg = trg.translate(str.maketrans('', '', string.punctuation)).lower().split()\n","  print(trg)\n","  trg.extend(['_'.join(ngram) for ngram in list(ngrams(trg, 2)) + list(ngrams(trg, 3))])\n","  \n","  VOCAB_stoi = vocs[row_idx]\n","  trg_intersection = set(VOCAB_stoi.keys()).intersection(set(trg))\n","  trg_vec = np.zeros(len(VOCAB_stoi))    \n","\n","  for word in trg_intersection:\n","      trg_vec[VOCAB_stoi[word]] = 1\n","\n","  for is_word in trg_vec:\n","      #res_file.write('{0},{1}\\n'.format(output_idx, int(is_word)))\n","      print('{0},{1}\\n'.format(output_idx, int(is_word)))\n","      output_idx += 1\n","\n","  print('')      \n","\n","  # with open(output_file, 'a') as res_file:\n","  #     for is_word in trg_vec:\n","  #         res_file.write('{0},{1}\\n'.format(output_idx, int(is_word)))\n","  #         output_idx += 1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uQ64P3nB-ZEe","colab_type":"code","colab":{}},"source":["titles = []\n","for abstract in abstracts:\n","    title, _ = translate_sentence(model, abstract.split())\n","    titles.append(' '.join(title).replace('<unk>', ''))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DV_z48okln0y","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"b6c98501-22b7-43c2-d6c1-f2b4e90b187c","executionInfo":{"status":"ok","timestamp":1578920778385,"user_tz":-180,"elapsed":314411,"user":{"displayName":"Bukin Ruslan","photoUrl":"","userId":"02589038028886526730"}}},"source":["import pandas as pd\n","from tqdm import tqdm\n","# test = pd.read_csv('../data/test.csv', encoding='utf8')\n","\n","titles = []\n","\n","for row in tqdm(test.iterrows(), desc=\"Iteration\", total = test.shape[0], position=0):\n","  i, text = row\n","  src, src_mask = convert_one_example(text[0], args.max_src_len, tokenizer)\n","  pred, _ = model.beam_decode(src.to(device), src_mask.to(device), 3, 3)\n","  # print(\" \".join(tokenizer.convert_ids_to_tokens(pred[0][0])).split('[SEP]')[0])\n","  s = ''\n","  for t in tokenizer.convert_ids_to_tokens(pred[0][0]):\n","    s += ' ' + t if not t.startswith('##') else t[2:]\n","  s = s.split('[SEP]')[0][1:]\n","  titles.append(s)\n"],"execution_count":68,"outputs":[{"output_type":"stream","text":["Iteration: 1000it [05:12,  2.82it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"w1K1X7B2-vhB","colab_type":"code","colab":{}},"source":["submission_df = pd.DataFrame({'abstract': test.abstract, 'title': titles})\n","submission_df.to_csv('predicted_titles.csv', index=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EGDsz4Pp0VNS","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7HMaLLNXBH-0","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}